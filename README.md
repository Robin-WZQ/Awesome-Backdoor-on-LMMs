# Awesome-Backdoor-on-LMMs

Awesome-Backdoor-on-LMMs is a collection of state-of-the-art, novel, exciting backdoor methods on LLMs. It contains papers, codes, datasets, evaluations, and analyses. Any additional things regarding backdoor, PRs, issues are welcome. Any problems, please contact wangzhongqi23s@ict.ac.cn. If you find this repository useful to your research or work, it is really appreciated to star this repository and cite our papers [here](#Reference). :sparkles:

## Reference

If you find this repository helpful for your research, we would greatly appreciate it if you could cite our papers. :sparkles:

```
@article{wang2025dynamicattentionanalysisbackdoor,
  title={Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models}, 
  author={Zhongqi Wang and Jie Zhang and Shiguang Shan and Xilin Chen},
  journal={arXiv preprint arXiv:2504.20518},
  year={2025},
}

@article{zhang2025twt,
  title={Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models}, 
  author={Jie Zhang and Zhongqi Wang and Shiguang Shan and Xilin Chen},
  journal={arXiv preprint arXiv:2503.17724},
  year={2025},
}

@InProceedings{10.1007/978-3-031-73013-9_7,
  author="Wang, Zhongqi
  and Zhang, Jie
  and Shan, Shiguang
  and Chen, Xilin",
  title="T2IShield: Defending Against Backdoors on Text-to-Image Diffusion Models",
  booktitle="Computer Vision -- ECCV 2024",
  year="2025",
  publisher="Springer Nature Switzerland",
  address="Cham",
  pages="107--124",
  isbn="978-3-031-73013-9"
}
```

## Bookmarks

- [Vision-Language Pretraining Models (VLPs)](#Vision-Language Pretraining Models (VLPs))
- 

## Papers

### Vision Language Pretrained Models (VLPs)

#### Backdoor Attack

| Time | Title | Venue |  Paper   |   Code   |
| ---- | ----- | :---: | :------: | :------: |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |

#### Backdoor Defense

| Time | Title | Venue |  Paper   |   Code   |
| ---- | ----- | :---: | :------: | :------: |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |

### Text Conditioned Diffusion Models (TDMs)

#### Backdoor Attack

| Time | Title | Venue |  Paper   |   Code   |
| ---- | ----- | :---: | :------: | :------: |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |

#### Backdoor Defense

| Time | Title | Venue |  Paper   |   Code   |
| ---- | ----- | :---: | :------: | :------: |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |

### Large Vision Language Models (LVLMs)

#### Backdoor Attack

| Time | Title | Venue |  Paper   |   Code   |
| ---- | ----- | :---: | :------: | :------: |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |

#### Backdoor Defense

| Time | Title | Venue |  Paper   |   Code   |
| ---- | ----- | :---: | :------: | :------: |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |
|      |       |       | [link]() | [code]() |

### VLM-based Embodied AI

#### Backdoor Attack

| Time    | Title                                                        |  Venue   |                            Paper                             |                        Code                         |
| ------- | ------------------------------------------------------------ | :------: | :----------------------------------------------------------: | :-------------------------------------------------: |
| 2025.05 | **BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization** |  Arxiv   |           [link](https://arxiv.org/abs/2505.16640)           |     [code](https://github.com/Zxy-MLlab/BadVLA)     |
| 2025.10 | **TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models** |  Arxiv   |           [link](https://arxiv.org/abs/2510.10932)           |   [code](https://github.com/megaknight114/TabVLA)   |
| 2025.11 | **AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models** |  Arxiv   |           [link](https://arxiv.org/abs/2511.12149)           |                          -                          |
| 2025.05 | **Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents** | EMNLP’25 |  [link](https://aclanthology.org/2025.findings-emnlp.411/)   |  [code](https://github.com/CTZhou-byte/AgentGhost)  |
| 2025.06 | **Poison Once, Control Anywhere: Clean-Text Visual Backdoors in VLM-based Mobile Agents** |  Arxiv   |           [link](https://arxiv.org/abs/2506.13205)           |                          -                          |
| 2025.07 | **VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation** | COLM‘25  | [link](https://openreview.net/forum?id=7HPuAkgdVm#discussion) |    [code](https://github.com/whi497/VisualTrap)     |
| 2025.09 | **Realistic Environmental Injection Attacks on GUI Agents**  |  Arxiv   |           [link](https://arxiv.org/abs/2509.11250)           | [code](https://github.com/zhangyitonggg/attack2gui) |



## Other Related Awesome Repository
